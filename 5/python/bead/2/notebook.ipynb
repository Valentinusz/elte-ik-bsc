{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Images/cisco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Internet Meter Anomaly Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "<li>**Part 1: Feature Engineering**</li>\n",
    "<li>**Part 2: Euclidean Anomaly Detection**</li>\n",
    "### Scenario/Background\n",
    "Anomaly-detection algorithms locate those datapoints that stand out from a pattern. For example, algorithms of this kind can be used to test the safety of airplane engines by recording quantities such as fuel consumption, temperature, and so on. Whenever the measurements display extreme values, such as unusually high temperature, anomaly detection alerts the operator, who can then take action to resolve potential issues. Constant improvement of safety standards is not unique to the transport sector, and these algorithms find applications in all branches of industry, from food manufacturing to the production of toys for children. \n",
    "### Required Resources\n",
    "* 1 PC with Internet access\n",
    "* Raspberry Pi version 2 or higher\n",
    "* Python libraries: numpy, pandas, matplotlib\n",
    "* Datafiles: rpi_data_processed.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import Python Libraries.\n",
    "In this step, you will import Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 1\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create a Dataframe and modify the quantities.\n",
    "The quantities that are recorded when gathering data, also known as features, may require some transformation before analysis. For example, the quantity called 'ping' obtained when measuring internet speed. This feature describes intervals of time. A contrast is then observed, as the other quantities being monitored, namely the rates of download and upload, have dimensions of **inverse** time. Because of this, 'ping' is not the optimal choice for statistical analysis. Better results are achieved using a related feature, which we will call 'ping rate'. This is calculated by applying the simple transformation $$\\mathrm{ping\\ rate} = \\frac{1}{\\mathrm{ping\\ time}}.$$\n",
    "This process of 'modifying' quantities in view of analysis is termed 'feature engineering', and is generally an important part of the machine-learning workflow. \n",
    "\n",
    "Load the internet-speed data from the file `rpi_data_processed.csv` into a Pandas dataframe named `df`. Using this as a starting point,  generate another dataframe, `df_rates`, whose three columns are `download_rate`, `upload_rate` and `ping_rate` respectively. When computing this last feature, make sure that the result is given in units of `1/seconds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code Cell 2\n",
    "# Load internet speed data\n",
    "df = pd.read_csv('./Data/rpi_data_processed.csv')\n",
    "\n",
    "# Initialize dataframe df_rates\n",
    "df_rates = df.drop(['Ping (ms)', 'Date', 'Time'], axis=1)\n",
    "\n",
    "# Rename the download and\n",
    "# upload columns of df_rates\n",
    "lookup = {'Download (Mbit/s)': 'download_rate', \n",
    "          'Upload (Mbit/s)': 'upload_rate'}\n",
    "df_rates = df_rates.rename(columns = lookup)\n",
    "\n",
    "# Calculate ping_rate\n",
    "ping_rate = 1. / df['Ping (ms)']\n",
    "\n",
    "# Convert ping_rate to 1/seconds\n",
    "ping_rate = 1000. * ping_rate\n",
    "\n",
    "# Add a column to complete the task\n",
    "df_rates['ping_rate'] = ping_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code Cell 3\n",
    "# Inspect the result\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:  Visualize the Data.\n",
    "\n",
    "It is reasonable to expect that the measured values of `download_rate`, `upload_rate` and `ping_rate` are concentrated around their averages. Observe the visualization below to see this. Use the sliders to change the angle and azimuth of the plot.\n",
    "\n",
    "**Optional** <br>\n",
    "Because internet-speed data only involve three different quantities, they are particularly simple to visualize. Machine-learning systems often exploit tens or even hundreds of features, which makes it difficult to create insightful plots. While drawing eloquent figures is not possible in many situations, interactive visualizations remain a great way of presenting data in front of an audience. You may then want to read and understand the code below, with the help of two comments: \n",
    "\n",
    "* The class `Axes3D` from `mpl_toolkits.mplot3d` allows you to generate 3-dimensional plots, extending the functionalities of the familiar `matplotlib.pyplot` module. \n",
    "* The method `interact`, which plays crucial role in animating the visualization, is obtained from `ipywidgets`. This module, in turn, is part of the `Ipython` environment for running Python interactively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 4\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 5\n",
    "def scatter_view(x, y, z, azim, elev):\n",
    "    # Init figure and axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "    \n",
    "    # Compute scatter plot\n",
    "    ax.scatter(x, y, z)\n",
    "    ax.set_xlabel('D rate (Mbit/s)', fontsize=16)\n",
    "    ax.set_ylabel('U rate (Mbit/s)', fontsize=16)\n",
    "    ax.set_zlabel('P rate (1/s)', fontsize=16)\n",
    "    \n",
    "    # Specify azimuth\n",
    "    # and elevation\n",
    "    ax.azim = azim\n",
    "    ax.elev = elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 6\n",
    "# Draw interactive plot\n",
    "xi = df_rates['download_rate']\n",
    "yi = df_rates['upload_rate']\n",
    "zi = df_rates['ping_rate']\n",
    "interact(lambda azim, elev: scatter_view(xi, yi, zi, azim, elev),\n",
    "         azim=(0, 90), elev=(0, 90))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Euclidean Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in the 3-dimensional plot above, anomalies are located far away from the 'average point'. The anomaly-detection system that we will discuss exploits this idea. Points that lie beyond a certain distance from the average will be considered anomalous, whereas all other will be deemed normal. \n",
    "\n",
    "For the sake of brevity, let us represent the coordinates `[download_rate, upload_rate, ping_rate]` of a datapoint as  $\\{x, y, z\\}$. Then, the distance of a measurement from the average location $\\{\\mu_{x}, \\mu_{y}, \\mu_{z}\\}$ is given by this formula:\n",
    "\n",
    "$$d = \\sqrt{(x - \\mu_x)^2 + (y-\\mu_y)^2 + (z - \\mu_z)^2},$$ \n",
    "\n",
    "This is the main ingredient of the anomaly detection system that we will build. As an aside, this ordinary concept of distance is termed **Euclidean**, to distinguish it from possible generalizations. Points such that $x$, $y$, or $z$ differ appreciably from the averages $\\mu_{x}$, $\\mu_{y}$, and $\\mu_{z}$, can be regarded as anomalies. \n",
    "\n",
    "#### Step 1: Calculate the means.\n",
    "Using a suitable Pandas function, calculate the list `mu`, whose elements are the average download, upload and ping rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 7\n",
    "mu = df_rates.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate the Euclidean distance.\n",
    "Find the Euclidean distance between each point and the average location. You may resort to the Numpy functions `np.square` and `np.sqrt`. These compute the [element-wise](http://www.glue.umd.edu/afs/glue.umd.edu/system/info/olh/Numerical/Matlab_Matrix_Manipulation_Software/Matrix_Vector_Operations/elementwise) square power and square root of any input array. Using element-wise functions makes it possible to calculate the distances without `for`-loops that iterate over the datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 8\n",
    "euclid_sq = np.square(df_rates - mu).sum(axis=1)\n",
    "euclid = np.sqrt(euclid_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create a histogram.\n",
    "Create a histogram of the distance separating each datapoint from the average location. Anomalies are then easily recognized in the 'tail' of the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 9\n",
    "# Histogram of Euclidean distance\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "# plot the histogram using 25 bins\n",
    "#plt.?(?, ?)\n",
    "\n",
    "plt.xlabel('Euclidean distance', fontsize=16)\n",
    "plt.ylabel('Relative frequency', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the normalized distance.\n",
    "It is helpful to work in terms of a **normalized distance**. This is the ratio of each distance over the maximum value of $d$. The furthest anomalous points, then, have a normalized distance of 1. Compute the normalized Euclidean distance for every point in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 10\n",
    "# Maximum Euclidean distance\n",
    "#max_euclid = ...\n",
    "# Normalized Euclidean distance\n",
    "#nmd_euclid = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Visualize the alarm rate.\n",
    "In order to label the points as normal and anomalous, you must define a **decision boundary**. It is necessary to select the distance beyond which points are deemed atypical. While the position of the boundary can be fixed on the basis of qualitative considerations, a quantitiative approach seems preferable. You can gradually increase decision distance, and monitor how the alarm rate varies. Specifically, the alarm rate is the number of anomalies divided by the total number of datapoints. This procedure 'tries out' all possible decision boundaries, allowing us to select the most appropriate one. \n",
    "\n",
    "Vary the normalized decision distance from 0 to 1, and record the alarm rate at each step. Store the values of normalized distance and alarm rate in the lists `nmd_range` and `ecl_alarm_rate` respectively. To visualize these results,  generate a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 11\n",
    "# Get alarm rate as a function\n",
    "# of normalized decision distance\n",
    "ecl_alarm_rate = []\n",
    "nmd_range = np.linspace(0, 1, 400)\n",
    "for nmd_decision in nmd_range:\n",
    "    # Count the number of values with a higher euclidean distance than \n",
    "    # the current decision boundary \n",
    "    # SOLUTION:\n",
    "    # num_fail = ...\n",
    "    ecl_alarm_rate.append(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 12\n",
    "# Plot number of alarms as a \n",
    "# function of decision distance\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "plt.plot(nmd_range, ecl_alarm_rate, linewidth=2)\n",
    "plt.xlabel('Normalized distance (Euclidean)', fontsize=16)\n",
    "plt.ylabel('Alarm rate', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Select the decision boundary.\n",
    "The plot above converts the problem of fixing a decision boundary in that of selecting the alarm rate. This is advantageous because the domain of application typically determines a sensible choice for the alarm rate. For example, when testing the safety of aeroplane engines, we may want to choose the alarm rate to be relatively high, so that both major and minor anomalies are detected, and the level of risk is kept low. \n",
    "\n",
    "Assume that, for this specific use-case, the optimal alarm rate is 0.1. Find the smallest normalized decision distance (`ecl_decision`) so that the alarm rate falls strictly below the threshold. Because the alarm rate at the selected decision boundary will not be precisely 0.1, store the exact rate in the variable `ecl_threshold`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Cell 13\n",
    "# Select decision boundary\n",
    "threshold = 0.1\n",
    "index, ecl_threshold = next(tpl for tpl in enumerate(ecl_alarm_rate) if tpl[1] < threshold)\n",
    "ecl_decision = nmd_range[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Visualize the decision boundary.\n",
    "Generate the plot from step 5 again, using a dot to mark the location of the decision boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code Cell 14\n",
    "# Alarm rate with decision boundary\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "# Plot the alarm rate as a function of the normalized euclidean distance\n",
    "#plt.plot(?, ?, linewidth=2)\n",
    "# Plot the chosen decision threshold and the curresponding alarm rate\n",
    "#plt.plot(?,?,'bo', markersize=11)\n",
    "\n",
    "plt.xlabel('Normalized distance (Euclidean)', fontsize=16)\n",
    "plt.ylabel('Alarm rate', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Visualize the decision boundary in 3D.\n",
    "Because our anomaly detection algorithm makes use of Euclidean distances, its decision boundaries, when visualized in three dimensions, are spherical. Examine the plot below to see this. We would also encourage you to read and understand the associated code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code Cell 15\n",
    "# Decision sphere (Polar coordinates)\n",
    "radius = ecl_decision * max_euclid\n",
    "phi = np.linspace(0, 2 * np.pi, 300)\n",
    "theta = np.linspace(0, 2 * np.pi, 300)\n",
    "\n",
    "# Decision sphere (Cartesian coordinates)\n",
    "xs = radius * np.outer(np.sin(theta), np.cos(phi))\n",
    "ys = radius * np.outer(np.sin(theta), np.sin(phi))\n",
    "zs = radius * np.outer(np.cos(theta), np.ones(np.size(phi)))\n",
    "\n",
    "# Center decision sphere at mean\n",
    "ecl_xd = xs + df_rates['download_rate'].mean()\n",
    "ecl_yd = ys + df_rates['upload_rate'].mean()\n",
    "ecl_zd = zs + df_rates['ping_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code Cell 16\n",
    "# Init figure and axes\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# Plot data\n",
    "ax.scatter(df_rates['download_rate'],\n",
    "           df_rates['upload_rate'], \n",
    "           df_rates['ping_rate'])\n",
    "\n",
    "# Plot decision boundary\n",
    "ax.plot_surface(ecl_xd, ecl_yd, ecl_zd,\n",
    "                linewidth=0, alpha=0.25)\n",
    "\n",
    "# Label axes\n",
    "ax.set_xlabel('D rate (Mbit/s)', fontsize=16)\n",
    "ax.set_ylabel('U rate (Mbit/s)', fontsize=16)\n",
    "ax.set_zlabel('P rate (1/s)', fontsize=16)\n",
    "    \n",
    "# --------------------------------------------------\n",
    "# Set equal aspect ratio for all axes\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Extreme values of x, y, z\n",
    "extremes = []\n",
    "extremes.append([df_rates['download_rate'].min(),\n",
    "                 df_rates['download_rate'].max()])\n",
    "extremes.append([df_rates['upload_rate'].min(),\n",
    "                 df_rates['upload_rate'].max()])\n",
    "extremes.append([df_rates['ping_rate'].min(),\n",
    "                 df_rates['ping_rate'].max()])\n",
    "\n",
    "# Half-widths and mid-points\n",
    "hwidths = [(row[1] - row[0]) / 2.0 for row in extremes]\n",
    "midpts = [(row[1] + row[0]) / 2.0 for row in extremes]\n",
    "\n",
    "# Set xlim, ylim, zlim\n",
    "left_ends = midpts - np.max(hwidths)\n",
    "right_ends = midpts + np.max(hwidths)\n",
    "ax.set_xlim([left_ends[0], right_ends[0]]);\n",
    "ax.set_ylim([left_ends[1], right_ends[1]]);\n",
    "ax.set_ylim([left_ends[2], right_ends[2]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='0.5'>&copy; 2017 Cisco and/or its affiliates. All rights reserved. This document is Cisco Public.<font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
